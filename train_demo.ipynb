{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "################ STRUCTURE ################\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 6), dtype=float32)\n",
      "Tensor(\"Identity:0\", shape=(?, 14, 14, 6), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 10, 10, 16), dtype=float32)\n",
      "Tensor(\"Identity_1:0\", shape=(?, 5, 5, 16), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"Identity_2:0\", shape=(?, 10), dtype=float32)\n",
      "###########################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b9a31519cf99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#                     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mplaceholder_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplaceholder_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0maccs\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alan/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alan/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alan/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Alan/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alan/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from layers import *\n",
    "from tools import *\n",
    "from models import *\n",
    "from dataProvider import *\n",
    "\n",
    "\n",
    "[train_data,train_label_map]=dataProvider('../data/cifar-10-train.npz').get_batch(is_reshaped=True)\n",
    "[valid_data,valid_label_map]=dataProvider('../data/cifar-10-valid.npz').get_batch(is_reshaped=True)\n",
    "\n",
    "\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    placeholder_input=tf.placeholder(tf.float32,[None,32,32,3],'holder_input')\n",
    "    placeholder_target=tf.placeholder(tf.float32,[None,10],'holder_target')\n",
    "    \n",
    "    conv1_layer=convolution_layer(inputs=placeholder_input,kernel_shape=[5,5,3,6],name='conv1_layer',reg_const=0.001)\n",
    "    conv1_out=conv1_layer.get_outputs(active=tf.nn.relu,padding='VALID')\n",
    "    \n",
    "    max1_layer=maxpooling_layer(inputs=conv1_out,name='max1_layer')\n",
    "    max1_out=max1_layer.get_outputs(padding='VALID',strides=[1,2,2,1])\n",
    "    \n",
    "    conv2_layer=convolution_layer(inputs=max1_out,kernel_shape=[5,5,6,16],name='conv2_layer',reg_const=0.001)\n",
    "    conv2_out=conv2_layer.get_outputs(active=tf.nn.relu,padding='VALID')\n",
    "    \n",
    "    max2_layer=maxpooling_layer(inputs=conv2_out,name='max2_layer')\n",
    "    max2_out=max2_layer.get_outputs(padding='VALID',strides=[1,2,2,1])\n",
    "    \n",
    "    conv3_layer=convolution_layer(inputs=max2_out,kernel_shape=[5,5,16,64],name='conv3_layer',reg_const=0.001)\n",
    "    conv3_out=conv3_layer.get_outputs(active=tf.nn.relu,padding='VALID')\n",
    "    \n",
    "    reshape1_layer=reshape_layer(inputs=conv3_out,name='reshape1_layer')\n",
    "    reshape1_out=reshape1_layer.get_outputs([-1,64])\n",
    "    \n",
    "    affine1_layer=affine_layer(inputs=reshape1_out,weights_shape=[64,128],name='affine1_layer',reg_const=0.001)\n",
    "    affine1_out=affine1_layer.get_outputs(tf.nn.relu)\n",
    "        \n",
    "    affine2_layer=affine_layer(inputs=affine1_out,weights_shape=[128,64],name='affine2_layer',reg_const=0.001)\n",
    "    affine2_out=affine2_layer.get_outputs(tf.nn.relu)\n",
    "        \n",
    "    affine3_layer=affine_layer(inputs=affine2_out,weights_shape=[64,10],name='affine3_layer',reg_const=0.001)\n",
    "    affine3_out=affine3_layer.get_outputs(tf.identity)\n",
    "    \n",
    "    print('################ STRUCTURE ################')\n",
    "    print(conv1_out)\n",
    "    print(max1_out)\n",
    "    print(conv2_out)\n",
    "    print(max2_out)\n",
    "    print(conv3_out)\n",
    "    print(reshape1_out)\n",
    "    print(affine1_out)\n",
    "    print(affine2_out)\n",
    "    print(affine3_out)\n",
    "    print('###########################################')\n",
    "    \n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=affine3_out,labels=placeholder_target))+sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    train_step=tf.train.AdamOptimizer().minimize(loss)\n",
    "    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(affine3_out,1),tf.argmax(placeholder_target,1)),tf.float32))\n",
    "    iteration=100\n",
    "    interval=5\n",
    "    storage={'index':[],'acc':[],'error':[],'conv1':[],'conv2':[],'conv3':[],'kernel1':[],'kernel2':[],'kernel3':[],'out':[]}\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(iteration):\n",
    "            errors=0.\n",
    "            accs=0.\n",
    "            index=0\n",
    "            for input_batch,target_batch in zip(train_data['inputs'],train_data['targets']):\n",
    "#                 if index==10:\n",
    "#                     break\n",
    "                feed={placeholder_input:input_batch,placeholder_target:target_batch}\n",
    "                _,e,a=sess.run([train_step,loss,acc],feed_dict=feed)\n",
    "                errors+=e\n",
    "                accs+=a\n",
    "                index+=1\n",
    "            errors/=index\n",
    "            accs/=index\n",
    "            if i%interval==0:\n",
    "                print('epoch # {0:02d}: training error = {1:.4f} training accuracy = {2:.4f}'.format(i+1,errors,accs))\n",
    "                c1,c2,c3,k1,k2,k3,o1=sess.run([conv1_layer.outputs,conv2_layer.outputs,conv3_layer.outputs,\n",
    "                                            conv1_layer.kernels,conv2_layer.kernels,conv3_layer.kernels,\n",
    "                                            affine3_layer.outputs\n",
    "                                           ],feed_dict={placeholder_input:train_data['inputs'][0],\n",
    "                                                        placeholder_target:train_data['targets'][0]})\n",
    "\n",
    "                storage['index'].append(i)\n",
    "                storage['acc'].append(a)\n",
    "                storage['error'].append(e)\n",
    "                storage['conv1'].append(c1)\n",
    "                storage['conv2'].append(c2)\n",
    "                storage['conv3'].append(c3)\n",
    "                storage['kernel1'].append(k1)\n",
    "                storage['kernel2'].append(k2)\n",
    "                storage['kernel3'].append(k3)\n",
    "                storage['out'].append(o1)\n",
    "                valid_err=0.\n",
    "                valid_acc=0.\n",
    "                valid_index=0\n",
    "                for input_batch,target_batch in zip(valid_data['inputs'],valid_data['targets']):\n",
    "#                     if valid_index==10:\n",
    "#                         break\n",
    "                    feed={placeholder_input:input_batch,placeholder_target:target_batch}\n",
    "                    e,a=sess.run([loss,acc],feed_dict=feed)\n",
    "                    valid_err+=e\n",
    "                    valid_acc+=a\n",
    "                    valid_index+=1\n",
    "                valid_err/=valid_index\n",
    "                valid_acc/=valid_index\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "                print('|epoch # {0:02d}: validation error = {1:.4f} validation accuracy = {2:.4f}|'.format(i+1,valid_err,valid_acc))\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "    np.save('results',storage)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "epoch # 01: training error = 2.3109 training accuracy = 0.0972\n",
      "--------------------------------------------------------------------------------------------\n",
      "|epoch # 01: validation error = 2.3027 validation accuracy = 0.0998|\n",
      "--------------------------------------------------------------------------------------------\n",
      "epoch # 06: training error = 2.3028 training accuracy = 0.0972\n",
      "--------------------------------------------------------------------------------------------\n",
      "|epoch # 06: validation error = 2.3026 validation accuracy = 0.1000|\n",
      "--------------------------------------------------------------------------------------------\n",
      "epoch # 11: training error = 2.3027 training accuracy = 0.0989\n",
      "--------------------------------------------------------------------------------------------\n",
      "|epoch # 11: validation error = 2.3027 validation accuracy = 0.0999|\n",
      "--------------------------------------------------------------------------------------------\n",
      "epoch # 16: training error = 2.3027 training accuracy = 0.0970\n",
      "--------------------------------------------------------------------------------------------\n",
      "|epoch # 16: validation error = 2.3026 validation accuracy = 0.1000|\n",
      "--------------------------------------------------------------------------------------------\n",
      "epoch # 21: training error = 2.3027 training accuracy = 0.0960\n",
      "--------------------------------------------------------------------------------------------\n",
      "|epoch # 21: validation error = 2.3026 validation accuracy = 0.0999|\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from layers import *\n",
    "from tools import *\n",
    "from models import *\n",
    "from dataProvider import *\n",
    "\n",
    "\n",
    "[train_data,train_label_map]=dataProvider('../data/cifar-10-train.npz').get_batch(is_reshaped=False)\n",
    "[valid_data,valid_label_map]=dataProvider('../data/cifar-10-valid.npz').get_batch(is_reshaped=False)\n",
    "\n",
    "\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    placeholder_input=tf.placeholder(tf.float32,[None,3072],'holder_input')\n",
    "    placeholder_target=tf.placeholder(tf.float32,[None,10],'holder_target')\n",
    "    \n",
    "    affine1_layer=affine_layer(inputs=placeholder_input,weights_shape=[3072,1024],name='affine1_layer',reg_const=0.001)\n",
    "    affine1_out=affine1_layer.get_outputs(tf.nn.relu)\n",
    "        \n",
    "    affine2_layer=affine_layer(inputs=affine1_out,weights_shape=[1024,1024],name='affine2_layer',reg_const=0.001)\n",
    "    affine2_out=affine2_layer.get_outputs(tf.nn.relu)\n",
    "        \n",
    "    affine3_layer=affine_layer(inputs=affine2_out,weights_shape=[1024,10],name='affine3_layer',reg_const=0.001)\n",
    "    affine3_out=affine3_layer.get_outputs(tf.identity)\n",
    "    \n",
    "#     print('################ STRUCTURE ################')\n",
    "#     print(conv1_out)\n",
    "#     print(max1_out)\n",
    "#     print(conv2_out)\n",
    "#     print(max2_out)\n",
    "#     print(conv3_out)\n",
    "#     print(reshape1_out)\n",
    "#     print(affine1_out)\n",
    "#     print(affine2_out)\n",
    "#     print(affine3_out)\n",
    "#     print('###########################################')\n",
    "    \n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=affine3_out,labels=placeholder_target))+sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    train_step=tf.train.AdamOptimizer().minimize(loss)\n",
    "    acc=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(affine3_out,1),tf.argmax(placeholder_target,1)),tf.float32))\n",
    "    iteration=100\n",
    "    interval=5\n",
    "#     storage={'index':[],'acc':[],'error':[],'conv1':[],'conv2':[],'conv3':[],'kernel1':[],'kernel2':[],'kernel3':[],'out':[]}\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(iteration):\n",
    "            errors=0.\n",
    "            accs=0.\n",
    "            index=0\n",
    "            for input_batch,target_batch in zip(train_data['inputs'],train_data['targets']):\n",
    "#                 if index==10:\n",
    "#                     break\n",
    "                feed={placeholder_input:input_batch,placeholder_target:target_batch}\n",
    "                _,e,a=sess.run([train_step,loss,acc],feed_dict=feed)\n",
    "                errors+=e\n",
    "                accs+=a\n",
    "                index+=1\n",
    "            errors/=index\n",
    "            accs/=index\n",
    "            if i%interval==0:\n",
    "                print('epoch # {0:02d}: training error = {1:.4f} training accuracy = {2:.4f}'.format(i+1,errors,accs))\n",
    "#                 c1,c2,c3,k1,k2,k3,o1=sess.run([conv1_layer.outputs,conv2_layer.outputs,conv3_layer.outputs,\n",
    "#                                             conv1_layer.kernels,conv2_layer.kernels,conv3_layer.kernels,\n",
    "#                                             affine3_layer.outputs\n",
    "#                                            ],feed_dict={placeholder_input:train_data['inputs'][0],\n",
    "#                                                         placeholder_target:train_data['targets'][0]})\n",
    "\n",
    "#                 storage['index'].append(i)\n",
    "#                 storage['acc'].append(a)\n",
    "#                 storage['error'].append(e)\n",
    "#                 storage['conv1'].append(c1)\n",
    "#                 storage['conv2'].append(c2)\n",
    "#                 storage['conv3'].append(c3)\n",
    "#                 storage['kernel1'].append(k1)\n",
    "#                 storage['kernel2'].append(k2)\n",
    "#                 storage['kernel3'].append(k3)\n",
    "#                 storage['out'].append(o1)\n",
    "                valid_err=0.\n",
    "                valid_acc=0.\n",
    "                valid_index=0\n",
    "                for input_batch,target_batch in zip(valid_data['inputs'],valid_data['targets']):\n",
    "#                     if valid_index==10:\n",
    "#                         break\n",
    "                    feed={placeholder_input:input_batch,placeholder_target:target_batch}\n",
    "                    e,a=sess.run([loss,acc],feed_dict=feed)\n",
    "                    valid_err+=e\n",
    "                    valid_acc+=a\n",
    "                    valid_index+=1\n",
    "                valid_err/=valid_index\n",
    "                valid_acc/=valid_index\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "                print('|epoch # {0:02d}: validation error = {1:.4f} validation accuracy = {2:.4f}|'.format(i+1,valid_err,valid_acc))\n",
    "                print('--------------------------------------------------------------------------------------------')\n",
    "    np.save('results',storage)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
